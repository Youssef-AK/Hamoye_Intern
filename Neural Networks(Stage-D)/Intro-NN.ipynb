{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (60000, 28, 28), (60000,)\n"
     ]
    }
   ],
   "source": [
    "print('Training data: {}, {}'.format(train_images.shape, train_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data: (10000, 28, 28), (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Test data: {}, {}'.format(test_images.shape, test_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 classes in dataset. They are: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "class_labels = np.unique(train_labels)\n",
    "\n",
    "print('There are {} classes in dataset. They are: {}'.format(len(class_labels), class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(train_images[0])\n",
    "plt.title('Label: {}'.format(train_labels[0]))\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(train_images[2500])\n",
    "plt.title('Label: {}'.format(train_labels[2500]))\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(train_images[12])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before scaling\n",
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images/ 255.0\n",
    "test_images = test_images/ 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
       "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
       "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
       "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
       "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
       "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
       "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
       "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
       "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
       "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
       "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
       "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After scaling\n",
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data to training and validation sets.\n",
    "x_train = train_images[0:50000]\n",
    "x_val = train_images[50000:]\n",
    "y_train = train_labels[0:50000]\n",
    "y_val = train_labels[50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (50000, 784)\n",
      "X_val: (10000, 784)\n",
      "test_images: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Reshape data from 28 * 28 array to a single array\n",
    "new_dimension = np.prod(train_images.shape[1:]) #np.prod() returns the product of array elements over a given axis.\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], new_dimension)\n",
    "x_val = x_val.reshape(x_val.shape[0], new_dimension)\n",
    "\n",
    "test_images = test_images.reshape(test_images.shape[0], new_dimension)\n",
    "\n",
    "print('X_train: {}'.format(x_train.shape))\n",
    "print('X_val: {}'.format(x_val.shape))\n",
    "print('test_images: {}'.format(test_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels to categorical variables\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "no_labels = 10\n",
    "y_train = to_categorical(y_train, no_labels)\n",
    "y_val = to_categorical(y_val, no_labels)\n",
    "y_test = to_categorical(test_labels, no_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\JK\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# placeholders are not enabled in tf 2\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs \n",
    "X = tf.placeholder(tf.float32, [None, new_dimension])\n",
    "Y = tf.placeholder(tf.float32, [None, no_labels])\n",
    "\n",
    "# create model architecture\n",
    "def multilayer_perceptron(x, no_classes, first_layer_neurons= 256, second_layer_neurons= 128):\n",
    "   \n",
    "    # first layer\n",
    "    first_weight = tf.Variable(tf.random_uniform([new_dimension, first_layer_neurons]))\n",
    "    first_bias = tf.Variable(tf.zeros([first_layer_neurons]))\n",
    "    first_layer_output = tf.nn.relu(tf.add(tf.matmul(x, first_weight), first_bias))\n",
    "    \n",
    "    # Second layer\n",
    "    second_weight = tf.Variable(tf.random_uniform([first_layer_neurons, second_layer_neurons]))\n",
    "    second_bias = tf.Variable(tf.zeros([second_layer_neurons]))\n",
    "    second_layer_output = tf.nn.relu(tf.add(tf.matmul(first_layer_output, second_weight), second_bias))\n",
    "    \n",
    "    # Output layer\n",
    "    final_weight = tf.Variable(tf.random_uniform([second_layer_neurons, no_classes]))\n",
    "    final_bias = tf.Variable(tf.zeros([no_classes]))\n",
    "    logits = tf.add(tf.matmul(second_layer_output, final_weight), final_bias)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\JK\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logits = multilayer_perceptron(X, no_labels)\n",
    "learn_rate = 0.01\n",
    "# Define the loss and optimiser for the network\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits= logits,\n",
    "                                                                labels= Y))\n",
    "optimiser = tf.train.AdamOptimizer(learning_rate= learn_rate)\n",
    "train_op = optimiser.minimize(loss_op)\n",
    "\n",
    "# Initialise the variables \n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 1000\n",
    "iteration = len(x_train) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch========0\n",
      "Epoch========1\n",
      "Epoch========2\n",
      "Epoch========3\n",
      "Epoch========4\n",
      "Epoch========5\n",
      "Epoch========6\n",
      "Epoch========7\n",
      "Epoch========8\n",
      "Epoch========9\n",
      "Epoch========10\n",
      "Epoch========11\n",
      "Epoch========12\n",
      "Epoch========13\n",
      "Epoch========14\n",
      "Epoch========15\n",
      "Epoch========16\n",
      "Epoch========17\n",
      "Epoch========18\n",
      "Epoch========19\n",
      "Accuracy: 0.9121000170707703\n"
     ]
    }
   ],
   "source": [
    "# Trian model\n",
    "with tf.Session() as session:\n",
    "  session.run(init)\n",
    "  for epoch in range(epochs):\n",
    "    average_cost = 0\n",
    "    start, end = 0, batch_size\n",
    "\n",
    "    for i in range(iteration):\n",
    "      batch_x, batch_y = x_train[start: end], y_train[start: end]\n",
    "      _, loss = session.run([train_op, loss_op], feed_dict={X: batch_x, Y: batch_y})\n",
    "      start += batch_size\n",
    "      end += batch_size \n",
    "      #average loss\n",
    "      average_cost += loss/iteration\n",
    "    print(\"Epoch========{}\".format(epoch))\n",
    "    \n",
    "  #evaluate model\n",
    "  prediction = tf.nn.softmax(logits)\n",
    "  ground_truth = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "  accuracy = tf.reduce_mean(tf.cast(ground_truth, \"float\"))\n",
    "  print(\"Accuracy: {}\".format(accuracy.eval({X: test_images, Y: y_test})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
